\chapter{Odporna optymalizacja regeneracyjna w sąsiedztwie}
\thispagestyle{chapterBeginStyle}

Jedną z podstawowych i bardzo wydajnych metod konstrukcji rozwiązań problemów optymalizacyjnych jest metoda oparta na przeszukiwaniu bezpośrednich \textbf{sąsiadów} aktualnie posiadanego rozwiązania z nadzieją, że takie krokowe zachowanie się algorytmu będzie skutkowało szybkim zbliżaniem się do optymalnego rozwiązania. W poniższym rozdziale wskażemy trzy takie metody, przy czym jedną z nich --- tą najefektywniejszą --- omówimy bardziej szczegółowo. Choć wydawać by się mogło, że taka metoda rozwiązywania problemów optymalizacyjnych nie ma prawa się dobrze zachowywać ze względu na bardzo silne założenia dotyczące sposobu zachowywania się rozwiązań sąsiednich do obecnie badanego, to właśnie takie algorytmy --- szczególnie \textbf{Tabu Search} --- są najogólniejszym sposobem na rozwiązywanie problemów optymalizacyjnych.

\section{Algorytm zachłanny}

\textbf{Algorytm zachłanny} jest najbardziej podstawową i naturalną strategią poszukiwania rozwiązania dla problemów optymalizacyjnych w myśl zasady ,,jeśli wartość mojego rozwiązania jest niewiele gorsza od wartości optymalnej, za pomocą niewielkich zmian powinienem tą wartość osiągnąć''. Fundament, na którym zbudowane jest to zdanie, zawiera bardzo ważne założenie określające charakter zachowania się poszczególnych rozwiązań problemu optymalizacyjnego. Zakładamy bowiem, że proporcjonalnie do zmian wprowadzonych w znalezionym rozwiązaniu, rośnie (bądź maleje) koszt takiego rozwiązania. Takim problemem jest na przykład rozpatrywany przez nas problem minimalnego drzewa rozpinającego, który leży u podstaw problemu, na którego rozwiązanie (aproksymację rozwiązania) poświęcimy cały poniższy rozdział:

\begin{equation}\label{eq:rrmst}
\min_{\mathclap{\textbf{x} \in X}} \left( v \left( \textbf{x}, \textbf{s} \right) + \max_{\mathclap{\textbf{s}^{\prime} \in S}} \min_{\mathclap{\textbf{y} \in X^{k}_{\textbf{x}}}} v \left( \textbf{y}, \textbf{s}^{\prime} \right) \right)
\end{equation}
\vspace*{-20pt}
\subsection{Sąsiedztwo}

Rozpoczniemy wyjątkowo od przedstawienia pseudokodu algorytmu zachłannego (zobacz Pseudokod \ref{alg:localsearch})\footnote{Ten i pozostałe pseudokody, chociaż dotyczące uniwersalnych algorytmów, będą przedstawiane z perspektywy problemu minimalnego drzewa rozpinającego (tak więc np. zamiast punktu startowego $x$ z dziedziny dopuszczalnych rozwiązań $X$, będziemy mieli początkowe drzewo rozpinające $T^{\ast}_{\textbf{s}}$). Dodatkowo, gdy będzie to uzasadnione, będziemy korzystać z wcześniej udowodnionego lematu \ref{lm:shrunkenGraph} (zamiast grafu $G = \left( V, E \right)$, będziemy odwoływać się do $G^{\ast} = \left( V, E^{\ast} \right)$).}, by następnie na jego podstawie wytłumaczyć pojęcie \textbf{sąsiedztwa}. Przypomnijmy, że funkcja $v \left( \bullet, \textbf{s} \right)$, zdefiniowana w drugim rozdziale, reprezentuje koszt rozwiązania problemu dla scenariusza $\textbf{s}$ (gdzie jako pierwszy parametr przekazywaliśmy jej binarny wektor $\textbf{x}$ reprezentujący to rozwiązanie). W odniesieniu do problemu minimalnego drzewa rozpinającego, zamiast wektora, będziemy przekazywać do niej drzewo --- wartością zaś tej funkcji będzie suma kosztów krawędzi należących do tego drzewa. Dla rozróżnienia kosztu rozwiązania problemu minimalnego drzewa rozpinającego w wersji \textsc{incremental} od tego dla wyrażenia \ref{eq:rrmst}, wprowadźmy oddzielne oznaczenia: $v_{\textsc{imst}} \left( \bullet, \textbf{s} \right)$ dla tego pierwszego oraz $v_{\textsc{rrmst}} \left( \bullet, S \right)$ dla problemu odpornej optymalizacji przyrostowej z możliwością poprawy (ang. \textsc{rrmst} --- \textit{Robust Recoverable Incremental Minimum Spanning Tree}). Należy wziąć pod uwagę, że policzenie wartości tego drugiego wyrażenie wymaga od nas w między czasie rozwiązania szeregu problemów \textsc{imst} oraz problemu adwersarza --- drugi z nich oraz sposób jego rozwiązania przedstawiliśmy w \ref{sec:adv}. Dlatego też zamiast przekazywać do funkcji pojedynczy scenariusz, tak jak to robiliśmy do tej pory, do wyrażenia $v_{\textsc{rrmst}} \left( \bullet, \bullet \right)$ będziemy przekazywać zbiór scenariuszy dla problemu adwersarza. Mając na uwadze dotychczas omówione zagadnienia, nie będziemy więcej wracać do problemu wyliczania wartości tej funkcji, skupimy się zaś na algorytmach zwracających aproksymację wyrażenia $\min_{\textbf{x} \in X} v_{\textsc{rrmst}} \left( \textbf{x}, S \right) = \min_{\textbf{x} \in X} \left( v \left( \textbf{x}, \textbf{s} \right) + \max_{\textbf{s}^{\prime} \in S} \min_{\textbf{y} \in X^{k}_{\textbf{x}}} v \left( \textbf{y}, \textbf{s}^{\prime} \right) \right)$.
\vspace*{-8pt}

\begin{pseudokod}
	\DontPrintSemicolon
	\SetKwInOut{Input}{Wejście}  
	\Input{
		$G^{\ast} = \left( V, E^{\ast} \right)$ --- graf ze zbiorem krawędzi $T^{\ast}_{\textbf{s}^{\prime}} \cup T^{\ast}_{\textbf{s}}$,\\
		$T^{\ast}_{\textbf{s}}$ --- początkowe minimalne drzewo rozpinające dla scenariusza $\textbf{s}$,\\
		$S$ --- zbiór scenariuszy adwersarza,\\
		$k$ --- parametr problemu \textsc{imst}.
	}
	\SetKwInOut{Result}{Wyjście}  
	\Result{$T^{\ast}$ --- lokalnie optymalne rozwiązanie problemu \textsc{imst}.}
	\Begin{
		Wybierz dowolne drzewo $T$, będące dopuszczalnym rozwiązaniem problemu \textsc{imst}.\;
		\While{znaleziono lepsze rozwiązanie}{
			$T \leftarrow \min \left\{ v_{\textsc{rrmst}} \left( T^{\prime}, S \right) \; : \; T^{\prime} \in N \left( T, T^{\ast}_{\textbf{s}}, k \right) \right\}$\;
			\uIf{$v_{\textsc{rrmst}} \left( T, S \right) < v_{\textsc{rrmst}} \left( T^{\ast}_{\textbf{s}}, S \right)$}{
				$T^{\ast}_{\textbf{s}} \leftarrow T$\;
			}
			\Else{
				\Return $T^{\ast}_{\textbf{s}}$\;	
			}
		}
	}
	\caption{\textsc{local-search} $\left( G^{\ast}, T^{\ast}_{\textbf{s}}, S, k \right)$}
	\label{alg:localsearch}
\end{pseudokod}
\vspace*{-8pt}

W przedstawionym pseudokodzie, linii $4$, jesteśmy zainteresowani pozyskaniem ze zbioru $N \left( T, T^{\ast}_{\textbf{s}}, k \right)$ najlepszego rozwiązania dopuszczalnego dla problemu \textsc{imst}. Jednocześnie, przekazując do niej drzewo $T$, chcemy aby zwrócone rozwiązanie było do niego w określony sposób podobne. Skalę tego podobieństwa dla różnych problemów definiujemy inaczej, dla problemu minimalnego drzewa rozpinającego jakim się zajmujemy, zbiór generowany przez powyższe wyrażenie przybierze formę:
\begin{equation}
	N \left( T, T^{\ast}_{\textbf{s}}, k \right) = \left\{ T^{\prime} : f \left( T^{\prime}, T^{\ast}_{\textbf{s}} \right) \leqslant k \; \wedge \; f \left( T^{\prime}, T \right) = 1 \right\}\text{,}
\end{equation}
i oznacza zbiór wszystkich tych drzew będących dopuszczalnymi rozwiązaniami problemu \textsc{imst} ($f \left( T^{\prime}, T^{\ast}_{\textbf{s}} \right) \leqslant k$), które jednocześnie są \textbf{sąsiadami} drzewa $T$. W naszym przypadku sąsiadem $T$ nazwiemy dowolne drzewo $T^{\prime}$, które różni się od tego pierwszego dokładnie jedną krawędzią. Wybór takiego drzewa $T^{\prime}$ spośród zbioru drzew $N \left( T, T^{\ast}_{\textbf{s}}, k \right)$ będziemy nazywać \textbf{ruchem} --- przejściem z jednego rozwiązania dopuszczalnego dla danego problemu do drugiego. Główna pętla algorytmu zachłannego \ref{alg:localsearch} będzie powtarzana do momentu, w którym żadne sąsiednie rozwiązanie nie okaże się lepsze od tego, na podstawie którego wygenerowaliśmy otoczenie (stąd sama nazwa algorytmu --- zachłanny). Powstaje naturalne pytanie --- jak generować kolejne drzewa rozpinające, które na dodatek są sąsiadami innego, wskazanego przez nas ($T$)? Jednym z pomysłów na realizację tego zadania może być konstrukcja nowych drzew poprzez dodawanie do nich krawędzi nie należących do $T$ a usuwaniu tych, które razem z dodaną przed chwilą krawędzią tworzą cykl~\cite{Kasperski2012}.

\begin{pseudokod}[!hbtp]
	\DontPrintSemicolon
	\SetKwInOut{Input}{Wejście}  
	\Input{
		$G = \left( V, E \right)$,\\
		$T$ --- minimalne drzewo rozpinające dla grafu $G$.
	}
	\SetKwInOut{Result}{Wyjście}  
	\Result{$N \left( T \right)$ --- otoczenie drzewa $T$.}
	\Begin{
		$N \left( T \right) \leftarrow \emptyset$\;
		\ForEach{$\left( i, j \right) \in E \setminus T$}{
			\ForEach{$e \in v_{i} \overset{T}{\leadsto} v_{j}$}{
				$N \left( T \right)	\leftarrow N \left( T \right) \cup \left( T \cup e_{ij} \setminus e \right)$\;
			}
		}
		\Return $N \left( T \right)$\;
	}
	\caption{\textsc{neighborhood} $\left( G, T \right)$}
	\label{alg:neighborhood}
\end{pseudokod}

Przez wyrażenie $e \in v_{i} \overset{T}{\leadsto} v_{j}$ (w linii $4$ pseudokodu \ref{alg:neighborhood}) rozumiemy wszystkie takie krawędzie $e$, które należą do ścieżki, której początek znajduje się w wierzchołku $v_{i}$ a kończy w $v_{j}$. Dodatkowo jesteśmy zainteresowani tylko takimi krawędziami, które należą do wskazanego przez nas drzewa $T$. Tą własność możemy bardzo łatwo wymusić, szukając ścieżek tylko w obrębie danego drzewa rozpinającego (jako że z definicji łączy ono ze sobą wszystkie krawędzie tak więc na pewno istnieje choć jedna ścieżka pomiędzy wskazanymi wierzchołkami $v_{i}$ oraz $v_{j}$). Algorytmem służącym nam do generowania takich zbiorów może być na przykład zmodyfikowany algorytm przeszukiwania wszerz~\cite[$604$--$606$]{Cormen}. Nasza modyfikacja polegałaby na tym, że zamiast jednej kolejki priorytetowej, posiadalibyśmy takich kolejek dwie, z czego pierwsza zachowałaby swoje oryginalne własności, elementami drugiej byłyby zbiory krawędzi reprezentujące ścieżki, które doprowadziły do konkretnego elementu z pierwszej listy, tak jak to pokazano na rysunkach od \ref{fig:bfsExample:a} do \ref{fig:bfsExample:d}.

\begin{savenotes}
	\begin{figure}
		\null\hfill
		\begin{subfigure}[b]{0.24\textwidth}
			\includegraphics[width=\textwidth]{Chapter_V/BFS-example/a}
			\caption{}
			\label{fig:bfsExample:a}
		\end{subfigure}
		\hfill
		\begin{subfigure}[b]{0.24\textwidth}
			\includegraphics[width=\textwidth]{Chapter_V/BFS-example/b}
			\caption{}
			\label{fig:bfsExample:b}
		\end{subfigure}
		\hfill
		\begin{subfigure}[b]{0.24\textwidth}
			\includegraphics[width=\textwidth]{Chapter_V/BFS-example/c}
			\caption{}
			\label{fig:bfsExample:c}
		\end{subfigure}
		\hfill
		\begin{subfigure}[b]{0.24\textwidth}
			\includegraphics[width=\textwidth]{Chapter_V/BFS-example/d}
			\caption{}
			\label{fig:bfsExample:d}
		\end{subfigure}
		\hfill\null
		\caption[Kolejne kroki zmodyfikowanego algorytmu \textsc{bfs} $\left( T, v_{s}, v_{t} \right)$]{
			Kolejne kroki zmodyfikowanego algorytmu \textsc{bfs} $\left( T, v_{s}, v_{t} \right)$ (ang. \textit{Breadth-first search}), gdzie $T$ jest drzewem rozpinającym graf $G$, $v_{s}$ oraz $v_{t}$ są odpowiednio wierzchołkami początkowym i końcowym ścieżki $v_{s} \leadsto v_{t}$, dla której chcemy wyznaczyć zbiór krawędzi należących do $T$ i do tej ścieżki.
			\textbf{(a)}~Początkowa sytuacja algorytmu dla $v_{s} = v_{2}$ i $v_{t} = v_{4}$. Na koniec kolejki $Q_{V}$ został dodany wierzchołek początkowy. Odpowiadający mu element w kolejce $V_{E}$ nie zawiera żadnych elementów.
			\textbf{(b)}~W wyniku zdjęcia z kolejki pierwszego elementu $v_{2}$, algorytm dodał do $Q_{V}$ wszystkie wierzchołki, do których prowadziły krawędzie ze zdjętego wierzchołka. Odpowiednio dla każdego takiego wierzchołka, do kolejki $Q_{E}$ zostały dodane krawędzie, dzięki którym algorytm do nich dotarł.
			\textbf{(c)}~Zgodnie z kolejnością ściągania elementów z kolejek, aktualnie badanymi elementami (zaznaczonymi w kolejce jasnym kolorem) są: wierzchołek $v_{1}$ oraz zbiór krawędzi $\left\{ e_{1} \right\}$. Z tego wierzchołka nie prowadzi jednak żadna nowa krawędź, badany wierzchołek nie jest też tym końcowym, toteż algorytm usuwa wskazane elementy.
			\textbf{(d)}~W wyniku wykonania operacji na kolejnej parze elementów: $\left( v_{4}, \left\{ e_{3} \right\} \right)$, do kolejki priorytetowej $Q_{V}$ został dodany\footnote{Jako że dodawany wierzchołek jest wierzchołkiem końcowym ścieżki $v_{s} \leadsto v_{t}$, zamiast aktualizować obydwie kolejki, możemy odpowiadający mu (wierzchołkowi $v_{t}$) zbiór krawędzi od razu przenieść do puli znalezionych ścieżek bez modyfikacji kolejek i przejść do następnego elementu.} nowy jeszcze nieodwiedzony wierzchołek $v_{5} = v_{t}$. Równolegle, do kolejki $Q_{E}$, dla dodanego wierzchołka, został dodany zbiór krawędzi będący sumą zbioru łuków, po których algorytm dotarł do analizowanego wierzchołka $v_{4}$, oraz łuku, po którym przeszedł on do nowego wierzchołka (zbiór $\left\{ e_{3}, e_{4} \right\}$). Fakt, że dodawany do kolejki $Q_{V}$ element jest wierzchołkiem końcowym w ścieżce $v_{s} \leadsto v_{t}$, oznacza że podany zbiór krawędzi jest jedną z możliwych ścieżek (w tym przypadku jedyną) pomiędzy tymi wierzchołkami. Algorytm kontynuujemy dopóki obie kolejki nie są puste, zapisując po drodze elementy z $Q_{E}$, które odpowiadają wierzchołkom $v_{t}$, dodawanym do kolejki $Q_{V}$.
		}
		\label{fig:bfsExample}
	\end{figure}
\end{savenotes}

\subsection{Wady algorytmu zachłannego}

Jak każdy algorytm zachłanny, i ten boryka się z tymi samymi problemami: lokalny charakter jego decyzji powoduje, że bardzo łatwo zatrzymać mu się w \textbf{lokalnym optimum} $T^{\ast}$, które charakteryzuje się tym, że dla dowolnego drzewa $T^{\prime} \in N \left( T, T^{\ast}_{\textbf{s}}, k \right)$ mamy $v_{\textsc{rrmst}} \left( T^{\ast}, S \right) \leqslant v_{\textsc{rrmst}} \left( T^{\prime}, S \right)$. W takiej sytuacji algorytm zachłanny oczywiście zakończy działanie z przekonaniem, że znalezione przez niego rozwiązanie jest optymalne globalnie, choć w rzeczywistości przeglądnięta przez niego przestrzeń rozwiązań dopuszczalnych jest bardzo mała i mogła ,,nie otrzeć'' się nawet o prawidłowe rozwiązanie. Oczywistą konsekwencją powyższego jest w pełni deterministyczny schemat działania takiego algorytmu, tak więc jakość otrzymanego rozwiązania w pełni zależy od zdanego przez nas początkowego drzewa $T^{\ast}_{\textbf{s}}$. Dodatkowo algorytm nie uczy się --- raz przeglądnięte przez niego rozwiązanie może być przeglądane dowolną liczbę razy, jeżeli zdarzy się, że dane rozwiązanie jest najlepsze w sąsiedztwie wielu innych drzew rozpinających. Jak zobaczymy w części poświęconej algorytmowi lokalnego przeszukiwania z listą ruchów zakazanych (ang. \textit{Tabu Search}), mimo tak licznych i poważnych wad, algorytm ten jeszcze nam posłuży do konstrukcji dużo lepszego algorytmu.

\section{Symulowane wyżarzanie}

Algorytm \textbf{symulowanego wyżarzania} (ang. \textit{Simulated annealing}) jest algorytmem mocno zbliżonym do poprzednio omawianego, jednak eliminuje pewne wady poprzedniego rozwiązania. Przede wszystkim, rezygnuje on z przeglądania wszystkich sąsiadów zadanego drzewa $T$ (co wymuszało na nas wyrażenie $\min \left\{ v_{\textsc{rrmst}} \left( T^{\prime}, S \right) \; : \; T^{\prime} \in N \left( T, T^{\ast}_{\textbf{s}}, k \right) \right\}$ w linii $4$ pseudokodu \ref{alg:localsearch}). Zamiast tego, algorytm wprowadza pojęcie \textbf{temperatury}, która jest składową miary prawdopodobieństwa wybrania konkretnego sąsiada drzewa $T$ z otoczenia $N \left( T, T^{\ast}_{\textbf{s}}, k \right)$. Na jej podstawie, zamiast przeglądać całość otoczenia $N \left( T, T^{\ast}_{\textbf{s}}, k \right)$, algorytm losuje z niego drzewo $T^{\prime}$, oblicza wartość takiego rozwiązania ($v_{\textsc{rrmst}} \left( T^{\prime}, \textbf{s} \right)$), oraz na podstawie tej danej oraz temperatury decyduje się na wybór takiego drzewa, bądź losuje następne, do momentu, w którym dane przekazane do funkcji wyliczającej prawdopodobieństwo wybrania danego rozwiązania $T^{\prime}$ jest dostatecznie wysokie. Algorytm rozpoczyna pracę od pewnej temperatury maksymalnej, a następnie ją sukcesywnie obniża, powodując spadek wartości obliczanych prawdopodobieństw~\cite{Nikulin2008}~\cite{Jany2015}.

Zaletami takiego rozwiązania w porównaniu do poprzedniego algorytmu są niewątpliwie: brak konieczności przeglądania wszystkich sąsiednich rozwiązań (przeglądamy kolejne losowe rozwiązania do momentu, w którym zdefiniowane wcześniej reguły pozwolą nam na wybranie danego rozwiązania) oraz większa odporność na pozostanie w obszarze lokalnego optimum (ze względu na wprowadzoną losowość wyboru następnego rozwiązania z sąsiedztwa). Nadal jednak taka szansa istnieje, dlatego skupimy się teraz na trzecim i najbardziej złożonym rozwiązaniu, które w zamian nie jest obarczone wadami poprzedników --- algorytmem lokalnego przeszukiwania z listą ruchów zakazanych.

\section{Przeszukiwanie z listą Tabu}

Algorytm \textsc{\textbf{Tabu Search}}~\cite{TabuSearch} swoją nazwę zawdzięcza wprowadzanemu przez siebie dodatkowemu elementowi jakim jest \textbf{lista ruchów zakazanych} (ang \textit{tabu list}). Taką listą będziemy nazywać zbiór ruchów, których z różnych względów bronimy algorytmowi wykonać w trakcie poszukiwania rozwiązania --- w ten sposób, jeżeli \textbf{kadencja} takiego elementu na liście \textit{tabu} będzie wystarczająco długa (przez pojęcie kadencji rozumiemy liczbę iteracji algorytmu jaką musi wykonać aby mieć możliwość ponownego wyboru zakazanego ruchu), zapewnimy sobie brak wpadania przez algorytm w cykle podczas poszukiwania rozwiązania\footnote{Analogicznie jak w omawianym wcześniej zmodyfikowanym algorytmie \textsc{bfs} $\left( T, v_{s}, v_{t} \right)$ (patrz rysunek \ref{fig:bfsExample}), tak w przypadku algorytmu \textsc{tabu search}, algorytm nie podejmie decyzji powtórzenia pewnych ruchów, gdyż będzie wiedział, że taki ruch już wykonał (można powiedzieć, że lista \textit{tabu} jest częściowym zapisem historii wykonywanych ruchów).}. Dodatkowo będziemy chcieli rozwiązać kwestię groźby trafienia i pozostania w lokalnym minimum --- aby temu zapobiegać, będziemy co jakiś czas resetować nasz algorytm, który w takiej formie (upraszając) można przyrównać do wielokrotnego uruchamiania algorytmu zachłannego, za każdym razem dla innych drzew początkowych. Przy tym wszystkim będziemy oczywiście chcieli abyśmy w przypadku odnalezienia najlepszego rozwiązania do tej pory, mogli ruch do niego prowadzący, ignorując listę ruchów zakazanych, wykonać. O rozwiązaniu będącym efektem wykonania zabronionego ruchu będziemy mówić, że spełniało one \textbf{kryterium aspiracji}.

Aby zapewnić sobie przegląd jak największej przestrzeni rozwiązań dopuszczalnych problemu \textsc{imst}, będziemy chcieli aby każde następne drzewo będące punktem wyjścia po restarcie algorytmu, było jak najbardziej oddalone od drzew do tej pory przeanalizowanych. Innymi słowy, będziemy chcieli zaradzić kolejnej wadzie, którą wykazaliśmy przy okazji analizy algorytmu zachłannego --- stosunkowo niewielkiego obszaru rozwiązań, które ten algorytm badał, zanim zatrzymywał się w lokalnym optimum. Dla algorytmu \textsc{tabu search} nie jest inaczej --- podczas jednego pełnego przebiegu jesteśmy w stanie przeanalizować niewielką tylko część dopuszczalnych rozwiązań, dlatego sztucznie będziemy wymuszać rozpoczynanie wyszukiwania rozwiązania od nowa, zaczynając szukać w zupełnie innych miejscach, tak jak to zaprezentowano na pseudokodzie \ref{alg:tabusearch}.

\subsection{Sąsiedztwo}

Analizując wspomniany przed chwilą pseudokod, nietrudno nie zauważyć, że w linijce $9$ nagromadziliśmy bardzo dużą liczbę warunków --- w tym miejscu założyliśmy również, że skoro jesteśmy zainteresowani tylko takim sąsiadem $T^{\prime}$ drzewa $T$, dla którego wartość $v_{\textsc{rrmst}} \left( T^{\prime}, S \right)$ jest najmniejsza spośród wszystkich wartości $v_{\textsc{rrmst}} \left( T^{\prime\prime}, S \right)$ dla drzew $T^{\prime\prime} \in N \left( T, T^{\ast}_{\textbf{s}}, k \right)$, to nie potrzebujemy pamiętać jednocześnie pozostałych drzew w sąsiedztwie\footnote{Tak jak na przykład pseudokod algorytmu \textsc{tabu search} w~\cite{Kasperski2012}, gdzie są rozdzielone kroki: wygenerowanie całego zbioru $N \left( T, T^{\ast}_{\textbf{s}}, k \right)$ a następnie wybranie z niego drzewa o jak najmniejszej wartości rozwiązania dla problemu \textsc{rrmst}.}. W naszym przypadku zatem drzewem $T_{N}$ jest drzewo które:

\begin{itemize}
	\item należy do bezpośredniego sąsiedztwa drzewa $T$ (różni się od niego dokładnie jedną krawędzią) oraz ma nie więcej niż $k$ krawędzi, które nie należą do drzewa początkowego $T^{\ast}_{\textbf{s}}$ ($T_{N} \in N \left( T, T^{\ast}_{\textbf{s}}, k \right)$),
	\begin{itemize}
		\item ruch polegający na przejściu od $T$ do innego dopuszczalnego rozwiązania $T_{N}$ nie znajduje się na liście \textsc{tabu} ($T^{\prime} \notin TABU$),
		\item lub wartość rozwiązania problemu \textsc{rrmst} dla drzewa $T_{N}$ jest lepsza (mniejsza) niż najmniejsza taka wartość znaleziona do tej pory (kryterium aspiracji --- $v_{\textsc{rrmst}} \left( T^{\prime}, S \right) < C^{\Delta\ast}$), 
	\end{itemize}
	\item $v_{\textsc{rrmst}} \left( T^{N}, S \right)$ zwraca najmniejszą wartość spośród wszystkich drzew, które spełniają wszystkie powyższe kryteria ($T_{N} \leftarrow \min arg_{T^{\prime}} \left\{ v_{\textsc{rrmst}} \left( T^{\prime}, S \right) \; : \dots \right\}$).
\end{itemize}

W przypadku, gdy zbiór $N \left( T, T^{\ast}_{\textbf{s}}, k \right)$ jest na tyle duży, że wykonanie powyższych obliczeń dla każdego drzewa należącego do tego zbioru w sposób nieakceptowalny wpływa na czas wykonywania się algorytmu, możemy zastosować dodatkowo \textbf{kryterium aspiracji plus}, które przyjmuje parametry:

\begin{itemize}
	\item $min$ --- najmniejsza liczba drzew z sąsiedztwa, które musimy przeglądnąć ($min = \min \left\{ min, \left| N \left( T, T^{\ast}_{\textbf{s}}, k \right) \right| \right\}$),
	\item $max$ --- liczba drzew ze zbioru $N \left( T, T^{\ast}_{\textbf{s}}, k \right)$, po którym przeglądnięciu musimy zwrócić drzewo, dla którego wartość wyrażenia $v_{\textsc{rrmst}} \left( \bullet, S \right)$ była najmniejsza do tej pory --- reszty drzew rozpinających nie przeglądamy ($max = \min \left\{ max, \left| N \left( T, T^{\ast}_{\textbf{s}}, k \right) \right| \right\}$),
	\item $v_{min}$ --- próg aspiracji, po którego przekroczeniu przez wartość $v_{\textsc{rrmst}} \left( \bullet, S \right)$ dla pierwszego drzewa (drzewo $T^{+}$ i niech będzie ono $i$'tym przeglądanym drzewem), będziemy przeglądać jeszcze $p$ następnych w kolejności sąsiadów drzewa $T$ ze zbioru $N \left( T, T^{\ast}_{\textbf{s}}, k \right)$, gdzie
	\item $p = \min \left\{ i + Plus, max \right\}$.
\end{itemize}

W takiej sytuacji, zamiast wykonywać obliczenia dla wszystkich drzew w sąsiedztwie, przerywamy je w chwili, gdy zajdą następujące warunki:

\begin{itemize}
	\item przeglądniemy $max$ drzew lub
	\begin{itemize}
		\item wartość funkcji $v_{\textsc{rrmst}} \left( \bullet, S \right)$ dla pewnego drzewa $T^{+}$ jest mniejsza bądź równa niż ustalony z góry parametr $v_{min}$ oraz
		\item wykonamy potrzebne obliczenia jeszcze dla $p$ następnych drzew, należących do $N \left( T, T^{\ast}_{\textbf{s}}, k \right)$.
	\end{itemize}
\end{itemize}

W tym przypadku, zwróconym drzewem $T_{N}$ będzie albo najlepsze spośród pierwszych $max$ drzew, albo pierwsze takie drzewo, dla którego $v_{\textsc{rrmst}} \left( \bullet, S \right) \leqslant v_{min}$ ($T^{+}$), gdzie $v_{min}$ jest parametrem stosowanego kryterium aspiracji, albo najlepsze znalezione po nim ($T_{N} = \min arg_{T^{\prime}} \left\{ v_{\textsc{rrmst}} \left( T^{\prime}, S \right) \; : T^{\prime} \in \left\{ T^{+}, T^{+2}, \dots, T^{+p} \right\} \right\}$).

\begin{pseudokod}
	\DontPrintSemicolon
	\SetKwInOut{Input}{Wejście}  
	\Input{
		$G = \left( V, E \right)$,\\
		$T^{\ast}_{\textbf{s}}$ --- początkowe minimalne drzewo rozpinające dla scenariusza $\textbf{s}$,\\
		$S$ --- zbiór scenariuszy adwersarza,\\
		$k$ --- parametr problemu \textsc{imst}.\\
		$it_{max}$ --- liczba iteracji, po której następuje zresetowanie algorytmu.
	}
	\SetKwInOut{Result}{Wyjście}  
	\Result{$T^{\Delta\ast}$ --- najlepsze znalezione do tej pory rozwiązanie problemu \textsc{rrmst}.}
	\Begin{
		$T \leftarrow \textsc{random-mst} \left( G \right)$\;
		$T^{\Delta\ast} \leftarrow T$\;
		$C^{\Delta\ast} \leftarrow v_{\textsc{rrmst}} \left( T, S \right)$\;
		$TABU \leftarrow \emptyset$\;
		$E^{c} \leftarrow T^{c}$\;
		$it \leftarrow 0$\;
		\While{nie zaszło kryterium zatrzymania}{
			$T_{N} \leftarrow \min arg_{T^{\prime}} \left\{ v_{\textsc{rrmst}} \left( T^{\prime}, S \right) \; : \; T^{\prime} \in N \left( T, T^{\ast}_{\textbf{s}}, k \right) \; \wedge \;  \left( T^{\prime} \notin TABU \; \vee \; v_{\textsc{rrmst}} \left( T^{\prime}, S \right) < C^{\Delta\ast} \right) \right\}$\;
			$C_{N} \leftarrow v_{\textsc{rrmst}} \left( T_{N}, S \right)$\;
			$it \leftarrow it + 1$\;
			\If{$C_{N} < C^{\Delta\ast}$}{
				$T^{\Delta\ast} \leftarrow T_{N}$\;	
				$C^{\Delta\ast} \leftarrow C_{N}$\;
				$E^{c} \leftarrow E^{c} \cup T_{N}^{c}$\;	
			}
			\uIf{$it > it_{max}$}{
				$T \leftarrow \textsc{random-mst} \left( \left( V, E^{c} \right) \right)$\;
				$C \leftarrow v_{\textsc{rrmst}} \left( T, S \right)$\;
				\If{$C < C^{\Delta\ast}$}{
					$T^{\Delta\ast} \leftarrow T$\;	
					$C^{\Delta\ast} \leftarrow C$\;	
				}	
				$TABU \leftarrow \emptyset$\;
				$E^{c} \leftarrow T^{c}$\;
				$it \leftarrow 0$\;		
			}
			\Else{
				$T \leftarrow T_{N}$\;
				\textsc{update-tabu} $\left( \right)$\;
			}
		}
		\Return $T^{\Delta\ast}$\;
	}
	\caption{\textsc{tabu-search} $\left( G, T, S, k, it_{max} \right)$}
	\label{alg:tabusearch}
\end{pseudokod}

\subsection{Losowe drzewo rozpinające i strategia dywersyfikacji}

Omawiając cele jakie chcemy zrealizować implementując algorytm \textsc{tabu search}, wspomnieliśmy także o chęci resetowania algorytmu i rozpoczynania jego pracy na nowo lecz z rozwiązaniem początkowym $T$ jak najdalej oddalonym od któregokolwiek drzewa, które pojawiło się w procesie wykonywania się iteracji poprzedniej. W tym celu wprowadziliśmy następujące oznaczenia: $E^{c}$ oraz $T^{c}$, gdzie ten pierwszy jest konstruowany z sumy tych drugich. $T^{c}$ zaś będziemy nazywali \textbf{alternatywą najgorszego przypadku} dla drzewa $T$ --- innymi słowy będzie to minimalne drzewo rozpinające (znalezione przez zwykły algorytm rozwiązujący problem \textsc{mst}) dla następującego scenariusza:

\begin{equation}
	c^{S^{-}}_{i} \left( T \right) = \left\{\begin{matrix}
	\max \left\{ c^{\textbf{s}}_{i} : \textbf{s} \in S \right\} & e_{i} \in T,\\ 
	\min \left\{ c^{\textbf{s}}_{i} : \textbf{s} \in S \right\} & e_{i} \notin T
	\end{matrix}\right. \qquad \forall i \in \left\{ 1, 2, \dots, m \right\}\text{.}
\end{equation}

Celem takiego zabiegu jest wymuszenie zwrócenia przez algorytm minimalnego drzewa rozpinającego, którego część wspólna z drzewem $T$ jest jak najmniejsza (czyli jednocześnie jest jak najbardziej oddalone od zbioru sąsiadów drzewa $T$ --- $\left\{ T^{\prime} \; : \; f \left( T^{\prime}, T \right) = 1 \right\}$). Widzimy, że ilekroć poprawiamy dotychczas odnalezione rozwiązanie (poza sytuacją, w której resetujemy algorytm i ,,przez przypadek'' nowo wygenerowane drzewo okazuje się być tym najlepszym --- linie $17$--$21$), do zbioru $E^{c}$ dołączamy krawędzie wygenerowanych alternatyw dla tych rozwiązań ($E^{c} \leftarrow E^{c} \cup T_{N}^{c}$). Taka strategia skutkuje tym, że po $it_{max}$ iteracjach rozpoczynamy poszukiwanie rozwiązania w zupełnie innym fragmencie przestrzeni rozwiązań dopuszczalnych, przez co mamy większą szansę ,,natknąć'' się na lokalne optimum, które jest również optymalne globalnie.

Generowanie losowych drzew rozpinających dany graf (linie $2$ oraz $17$) jest zadaniem prostym --- w tym przypadku również możemy skorzystać ze zmodyfikowanej wersji algorytmu \textsc{bfs}, bądź dowolnego innego, błądzącego po grafie w sposób losowy (choć istnieją algorytmy od nich efektywniejsze~\cite{Wilson:1996:GRS:237814.237880}). Najprostsza implementacja wraz z odwiedzaniem kolejnych krawędzi po prostu losowo wybiera wychodzącą z niego krawędź spośród dostępnych, dbając o to aby zakończyć ten proces w chwili wybrania ostatniej $ \left| V \right| - 1$'ej krawędzi (odwiedzając przy tym każdy wierzchołek tylko raz).

\subsection{Lista ruchów zakazanych i kryterium końca}

Ostatnim elementem wymagającym omówienia jest lista \textsc{tabu}. Dzięki niej jesteśmy w stanie uniknąć zbyt częstego powtarzania tych samych ruchów czy wymusić na algorytmie przegląd coraz to dalszego sąsiedztwa danego drzewa początkowego w kolejnych iteracjach. Niestety, zastosowanie listy ruchów zakazanych ma swoje wady: fakt istnienia takiej listy może oznaczać, że w pewnych sytuacjach najbardziej optymalny ruch jest zakazany i nie będziemy mogli go wykonać (prawdopodobieństwo takiego zdarzenia jest tym większe im na dłuższe kadencje się zdecydujemy). Przeciwdziałać takim przypadkom ma, wprowadzone przez nas, kryterium aspiracji, które w sytuacjach takich jak opisana pozwala nam całkowicie zignorować listę \textsc{tabu}. Wokół samego wyboru długości kadencji poszczególnych elementów listy gromadzi się wiele problemów; z jednej strony powiedzieliśmy, że zbyt długie cykle mogą powodować pomijanie pewnych optymalnych rozwiązań, lecz dzięki temu, że niektóre ruchy są zakazane przez bardzo długi okres, mamy szansę przeglądnąć szerszy obszar rozwiązań dopuszczalnych wokół punktu startowego. Pociąga to za sobą również wady --- przeszukując coraz to większy obszar przy niezmiennej liczbie iteracji tracimy na jakości uzyskiwanych wyników (badany zbiór rozwiązań jest rzadszy przez co większe jest prawdopodobieństwo pominięcia rozwiązania, które powinniśmy wybrać). Z kolei skłanianie się ku krótkim kadencjom podnosi co prawda naszą szansę na znalezienie optymalnego rozwiązania, lecz wraz z nią rośnie zagrożenie, że zwróconym rozwiązaniem będzie optimum lokalne, bądź wpadnięcia w cykl.

Z każdą następną iteracją, wraz z wywołaniem procedury \textsc{update-tabu}, pozostały czas kadencji każdego z elementów powinien ulec zmniejszeniu, zaś ruchy, których czas kadencji dobiegł końca --- usunięte z listy, co czyni je ponownie możliwymi do wyboru. Dodatkowo, jako najprostsze kryterium końca algorytmu, możemy przyjąć warunek sprawdzający czy całkowita liczba iteracji nie została przekroczona. Jeżeli tak, zwrócimy najlepsze do tej pory odnalezione rozwiązanie.

\subsection{Podsumowanie rozdziału}

Algorytm \textsc{tabu search} jest tylko ideą --- większa część pokazanego pseudokodu jest opcjonalna i tylko od tego do jakiego problemu się tę ideę zastosuje zależy finalny kształt tego algorytmu. Wszystkie podane parametry, takie jak okres kadencji, liczba iteracji, kryterium zatrzymania się algorytmu czy też parametry aspiracji plus --- powinny być rozpatrywane dla każdego problemu oddzielnie i nie istnieje ogólna formuła wskazująca ich wartości.

ff
df
ffdfd
fd